{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1. Tensors.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO0fezQxTwP0y/3BJsl7L//"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"d4avBqFjPKcH","colab_type":"text"},"source":["# PyTorch\n","\n","In PyTorch, the computational graph is built up as you execute the code, as opposed to TensorFlow where you define your graph and then run it. \n","In PyTorch, you create your graph by running it."]},{"cell_type":"markdown","metadata":{"id":"m9fmRqJ6O_PJ","colab_type":"text"},"source":["# Tensors\n","\n","Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."]},{"cell_type":"code","metadata":{"id":"YH9UhdxVytb1","colab_type":"code","colab":{}},"source":["import torch\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fczh3pyhP2fa","colab_type":"text"},"source":["Construct a matrix filled zeros and of dtype long:\n","\n","![alt text](https://drive.google.com/uc?id=1mTiCspjN9hYj-PoiRpBiFLnb9izOVIqq)\n"]},{"cell_type":"code","metadata":{"id":"R5VHvt48y-sL","colab_type":"code","outputId":"1c49bf8f-ec05-4eb7-c81f-9328b532bdbf","executionInfo":{"status":"ok","timestamp":1590592756012,"user_tz":-330,"elapsed":6980,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["x = torch.zeros(5, 3, dtype = torch.long)\n","print(x)\n","y = torch.zeros((5, 3), dtype = torch.long) # notice that both x and y have similar values\n","print(y)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]])\n","tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gv4Kvyp7QNep","colab_type":"text"},"source":["*Get* size of `x` using either `x.size()` or `x.shape`:"]},{"cell_type":"code","metadata":{"id":"c6_XQN5jQQov","colab_type":"code","outputId":"4d2620dc-7ab0-40f3-9c98-5bb608b2a639","executionInfo":{"status":"ok","timestamp":1590592756013,"user_tz":-330,"elapsed":6955,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(x.size())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["torch.Size([5, 3])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dYdkLK7tQTxn","colab_type":"text"},"source":["**Note:** `torch.Size` is in fact a tuple, so it supports all tuple operations."]},{"cell_type":"code","metadata":{"id":"ZMsJrEmcQmm4","colab_type":"code","outputId":"ec669516-b7cb-4144-afaa-38f972157f8b","executionInfo":{"status":"ok","timestamp":1590592756014,"user_tz":-330,"elapsed":6938,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["a, b = x.size()\n","print(a)\n","print(b)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["5\n","3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBftK7ArBvPk","colab_type":"code","outputId":"62fa2020-6ea9-4bd9-a520-058106f35001","executionInfo":{"status":"ok","timestamp":1590592756016,"user_tz":-330,"elapsed":6920,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["print(x.shape)\n","print(x.size())\n","print(y.shape)\n","print(x == y)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([5, 3])\n","torch.Size([5, 3])\n","torch.Size([5, 3])\n","tensor([[True, True, True],\n","        [True, True, True],\n","        [True, True, True],\n","        [True, True, True],\n","        [True, True, True]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aTJnUIPKPl2j","colab_type":"text"},"source":["An uninitialized matrix is declared, but does not contain definite known values before it is used. When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values.\n","\n","Construct a 5x3 matrix, uninitialized:"]},{"cell_type":"code","metadata":{"id":"6MPbqcv-yyOb","colab_type":"code","outputId":"9d8ad654-7b75-4279-d595-e78fdee19fd7","executionInfo":{"status":"ok","timestamp":1590592756017,"user_tz":-330,"elapsed":6900,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["x = torch.empty(5, 3)\n","print(x)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["tensor([[5.0173e-36, 0.0000e+00, 3.3631e-44],\n","        [0.0000e+00,        nan, 0.0000e+00],\n","        [1.1578e+27, 1.1362e+30, 7.1547e+22],\n","        [4.5828e+30, 1.2121e+04, 7.1846e+22],\n","        [9.2198e-39, 7.0374e+22, 0.0000e+00]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-71G5B7wPyP4","colab_type":"text"},"source":["Construct a randomly initialized matrix:"]},{"cell_type":"code","metadata":{"id":"FBGpPYhuy4Rb","colab_type":"code","outputId":"996892a9-b2fb-4d2d-b2c8-082dc77b536d","executionInfo":{"status":"ok","timestamp":1590592756018,"user_tz":-330,"elapsed":6886,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["x = torch.rand(5, 3)\n","print(x)\n","y = torch.rand((5, 3))\n","print(y)\n","print(x.shape)\n","print(x.size())\n","print(y.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tensor([[0.0097, 0.3371, 0.2936],\n","        [0.0634, 0.1718, 0.2978],\n","        [0.1646, 0.4859, 0.8145],\n","        [0.9422, 0.7910, 0.9739],\n","        [0.3337, 0.4996, 0.0296]])\n","tensor([[0.0417, 0.4654, 0.8836],\n","        [0.4664, 0.6991, 0.9959],\n","        [0.5893, 0.8863, 0.7308],\n","        [0.6408, 0.1174, 0.1627],\n","        [0.1935, 0.9692, 0.0025]])\n","torch.Size([5, 3])\n","torch.Size([5, 3])\n","torch.Size([5, 3])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y8JRm8VRVtps","colab_type":"text"},"source":["Construct an Identity matrix"]},{"cell_type":"code","metadata":{"id":"2oCHY0LvVx4C","colab_type":"code","outputId":"a41f9d9d-652a-4592-cf0c-49cfe99b9534","executionInfo":{"status":"ok","timestamp":1590592756019,"user_tz":-330,"elapsed":6868,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["x = torch.eye(5, 5)\n","print(x)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([[1., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0.],\n","        [0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1.]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Nqyu45ESP5J5","colab_type":"text"},"source":["Construct a tensor directly from data:\n","\n","`torch.tensor(data, dtype=None, device=None, requires_grad=False pin_memory=False)` → Tensor\n","\n","Constructs a tensor with `data`.\n","\n","![alt text](https://drive.google.com/uc?id=1YzeBactU2MQXI9q0dNJ3Q39cd6qD0oPb)\n"]},{"cell_type":"code","metadata":{"id":"lhSTrKpBzJkT","colab_type":"code","outputId":"cf0a1f84-feb3-4116-d8b6-b4074f7898e1","executionInfo":{"status":"ok","timestamp":1590592756020,"user_tz":-330,"elapsed":6851,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n","print(x)\n","print(x.size())"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor([[1, 2, 3],\n","        [4, 5, 6]])\n","torch.Size([2, 3])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tJr3TGMAP9R8","colab_type":"text"},"source":["Or create a tensor based on an existing tensor. These methods will reuse properties of the input tensor, e.g. dtype, unless new values are provided by user"]},{"cell_type":"code","metadata":{"id":"13mPMEhpzbez","colab_type":"code","outputId":"0538e803-2bf0-4773-8456-15f9f1d49dcc","executionInfo":{"status":"ok","timestamp":1590592756021,"user_tz":-330,"elapsed":6838,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["x = x.new_ones(5, 3, dtype=torch.double)      # new_* methods take in sizes\n","print(x)\n","\n","x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n","print(x)                                      # result has the same size\n","\n","# rand_like will inherit all the attributes from its argument's tensor.\n","# This is true in general for any *_like() methods.\n","# Some of the other useful methods are torch.ones_like() and torch.zeros_like(). "],"execution_count":10,"outputs":[{"output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)\n","tensor([[-1.4660, -1.6301, -1.4368],\n","        [-0.2555,  0.4440, -0.7693],\n","        [-0.4597, -1.6205,  0.2796],\n","        [-1.5583,  0.1140,  1.6616],\n","        [ 1.5929, -1.5526,  0.0489]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ftwYUSnERLDR","colab_type":"text"},"source":["## Operations\n","There are multiple syntaxes for operations. In the following example, we will take a look at the addition operation.\n","\n","Addition: syntax 1"]},{"cell_type":"code","metadata":{"id":"JL34ZmJgRVMZ","colab_type":"code","outputId":"1f049b76-d788-4e1a-9723-c5c06112757f","executionInfo":{"status":"ok","timestamp":1590592756022,"user_tz":-330,"elapsed":6826,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["y = torch.rand(5, 3)\n","print(x + y)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tensor([[-1.4152, -1.4416, -0.7250],\n","        [ 0.4058,  0.7322, -0.1084],\n","        [-0.2204, -0.8886,  0.8981],\n","        [-0.8824,  0.8038,  2.0714],\n","        [ 2.4004, -0.8462,  0.2737]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5tO1PNl7RbWf","colab_type":"text"},"source":["Addition: syntax 2"]},{"cell_type":"code","metadata":{"id":"KFJ5l8ZdRcqx","colab_type":"code","outputId":"2d8a91da-2a11-4ac1-c182-d792ecf70252","executionInfo":{"status":"ok","timestamp":1590592756023,"user_tz":-330,"elapsed":6811,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["print(torch.add(x, y))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["tensor([[-1.4152, -1.4416, -0.7250],\n","        [ 0.4058,  0.7322, -0.1084],\n","        [-0.2204, -0.8886,  0.8981],\n","        [-0.8824,  0.8038,  2.0714],\n","        [ 2.4004, -0.8462,  0.2737]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UOlYc43eRe0H","colab_type":"text"},"source":["Addition: providing an output tensor as argument"]},{"cell_type":"code","metadata":{"id":"RAHzFWnNRhco","colab_type":"code","outputId":"991bdf86-5133-48d5-aac3-7eef622b2f5c","executionInfo":{"status":"ok","timestamp":1590592756024,"user_tz":-330,"elapsed":6797,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["result = torch.empty(5, 3)\n","torch.add(x, y, out=result)\n","print(result)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor([[-1.4152, -1.4416, -0.7250],\n","        [ 0.4058,  0.7322, -0.1084],\n","        [-0.2204, -0.8886,  0.8981],\n","        [-0.8824,  0.8038,  2.0714],\n","        [ 2.4004, -0.8462,  0.2737]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5Dn8ghx_EWAR","colab_type":"text"},"source":["Addition: syntax 3"]},{"cell_type":"code","metadata":{"id":"b2cTBPNVEXyM","colab_type":"code","outputId":"4c5c1fa3-bea8-4e74-9aff-81eee82356fd","executionInfo":{"status":"ok","timestamp":1590592756025,"user_tz":-330,"elapsed":6785,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# adds 1 to y\n","print(y.add(1)) # also an example of \"broadcasting\" in PyTorch"],"execution_count":14,"outputs":[{"output_type":"stream","text":["tensor([[1.0507, 1.1885, 1.7117],\n","        [1.6613, 1.2881, 1.6609],\n","        [1.2393, 1.7319, 1.6185],\n","        [1.6760, 1.6898, 1.4098],\n","        [1.8075, 1.7065, 1.2247]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vvmlYVtVRj44","colab_type":"text"},"source":["Addition: in-place"]},{"cell_type":"code","metadata":{"id":"q7BSKTF1RwPy","colab_type":"code","outputId":"3aeb695a-dda3-465c-e2eb-55eef4e7db47","executionInfo":{"status":"ok","timestamp":1590592756026,"user_tz":-330,"elapsed":6773,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# adds x to y\n","y.add_(x)\n","print(y)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["tensor([[-1.4152, -1.4416, -0.7250],\n","        [ 0.4058,  0.7322, -0.1084],\n","        [-0.2204, -0.8886,  0.8981],\n","        [-0.8824,  0.8038,  2.0714],\n","        [ 2.4004, -0.8462,  0.2737]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rxz_CKrRRxFh","colab_type":"text"},"source":["**Note:** Any operation that mutates a tensor in-place is post-fixed with an `_`. For example:` x.copy_(y), x.t_(),` will change `x`."]},{"cell_type":"markdown","metadata":{"id":"lnoHENFNDAqN","colab_type":"text"},"source":["Matrix Multiplication, Transpose and Inverse is similar to NumPy with slight variations"]},{"cell_type":"code","metadata":{"id":"MBSdzYkODQVK","colab_type":"code","outputId":"841a5e48-d898-4a9d-d358-21a1818faa92","executionInfo":{"status":"ok","timestamp":1590592756030,"user_tz":-330,"elapsed":6764,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["m1 = torch.randn((5, 3))\n","m2 = torch.randn((5, 3))\n","print(m2.t() @ m1) # In NumPy this is equivalent to print(m2.T @ m1)\n","print(torch.inverse(m2.t() @ m1)) # In NumPy this is equivalent to print(inv(m2.T @ m1))\n","print((m2.t()).mm(m1)) # We can also use the mm() method to do matrix multiplications"],"execution_count":16,"outputs":[{"output_type":"stream","text":["tensor([[ 1.5106,  0.7047,  0.1931],\n","        [-1.3575,  0.3428,  0.8860],\n","        [-2.6322,  0.3797, -0.1784]])\n","tensor([[ 0.1699, -0.0851, -0.2385],\n","        [ 1.1002, -0.1020,  0.6840],\n","        [-0.1653,  1.0378, -0.6301]])\n","tensor([[ 1.5106,  0.7047,  0.1931],\n","        [-1.3575,  0.3428,  0.8860],\n","        [-2.6322,  0.3797, -0.1784]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rAXpbIMySSoQ","colab_type":"text"},"source":["You can use standard NumPy-like indexing with all bells and whistles!"]},{"cell_type":"code","metadata":{"id":"Ft4KCRwxSJlV","colab_type":"code","outputId":"38339213-7468-4b89-816c-5bb66572b4f1","executionInfo":{"status":"ok","timestamp":1590592756031,"user_tz":-330,"elapsed":6708,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(x[:, 1])"],"execution_count":17,"outputs":[{"output_type":"stream","text":["tensor([-1.6301,  0.4440, -1.6205,  0.1140, -1.5526])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GOR2GyNcSU1R","colab_type":"text"},"source":["Resizing: If you want to resize/reshape tensor, you can use `torch.view`:"]},{"cell_type":"code","metadata":{"id":"WKN3JOGXSYPy","colab_type":"code","outputId":"780b65d7-f06b-4669-8134-f9602e32ec87","executionInfo":{"status":"ok","timestamp":1590592756032,"user_tz":-330,"elapsed":6688,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n","print(x.size(), y.size(), z.size())"],"execution_count":18,"outputs":[{"output_type":"stream","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RN3cn9NxScCR","colab_type":"text"},"source":["If you have a one element tensor, use `.item()` to get the value as a Python number"]},{"cell_type":"code","metadata":{"id":"RyXSBWBJSaXB","colab_type":"code","outputId":"102135a2-056f-451d-94b1-00494010532e","executionInfo":{"status":"ok","timestamp":1590592756033,"user_tz":-330,"elapsed":6673,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["x = torch.randn(1)\n","print(x)\n","print(x.item())\n","# temp = torch.rand(5, 3)\n","# print(temp)\n","# print(temp.item()) -> Throws this error : ValueError: only one element tensors can be converted to Python scalars"],"execution_count":19,"outputs":[{"output_type":"stream","text":["tensor([0.3653])\n","0.365324467420578\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6wmW5QtmwErh","colab_type":"text"},"source":["### Broadcasting in PyTorch\n","\n","Broadcasting in PyTorch is similar to broadcasting in NumPy"]},{"cell_type":"code","metadata":{"id":"yZF0OfMpwhIK","colab_type":"code","outputId":"2c7ad777-dc84-4ba9-922c-1bc34d3f4fac","executionInfo":{"status":"ok","timestamp":1590592756034,"user_tz":-330,"elapsed":6661,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":510}},"source":["x = torch.ones((5, 3))\n","print(x)\n","print(\"*\" * 65)\n","\n","print(x + 1)\n","print(x.add(1))\n","print(\"*\" * 65)\n","\n","print(x * 3)\n","print(\"*\" * 65)\n","\n","print((x + 1) ** 2) \n","print(\"*\" * 65)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]])\n","*****************************************************************\n","tensor([[2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.]])\n","tensor([[2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.],\n","        [2., 2., 2.]])\n","*****************************************************************\n","tensor([[3., 3., 3.],\n","        [3., 3., 3.],\n","        [3., 3., 3.],\n","        [3., 3., 3.],\n","        [3., 3., 3.]])\n","*****************************************************************\n","tensor([[4., 4., 4.],\n","        [4., 4., 4.],\n","        [4., 4., 4.],\n","        [4., 4., 4.],\n","        [4., 4., 4.]])\n","*****************************************************************\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s1KpS8-bSgT4","colab_type":"text"},"source":["**Read Later:** 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc., are described [here](https://pytorch.org/docs/torch)."]},{"cell_type":"markdown","metadata":{"id":"qwwpDtYNFJsB","colab_type":"text"},"source":["### Some more useful methods of `torch`\n","\n","### `torch.gather`\n","\n","Gathers values along an axis specified by dim.\n","\n","For a 3-D tensor the output is specified by:\n","\n","```\n","out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n","out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n","out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n","```\n","\n","*Parameters*\n","\n","* **input** (`Tensor`) – the source tensor\n","\n","* **dim** (`int`) – the axis along which to index\n","\n","* **index** (`LongTensor`) – the indices of elements to gather\n","\n","* **out** (`Tensor`, optional) – the destination tensor\n","\n","* **sparse_grad** (`bool`, optional) – If `True`, gradient w.r.t. `input` will be a sparse tensor."]},{"cell_type":"code","metadata":{"id":"3Gyv1RBhGYSw","colab_type":"code","outputId":"6f9fa5f1-e9ab-44e8-bcc5-453c433857cb","executionInfo":{"status":"ok","timestamp":1590592756035,"user_tz":-330,"elapsed":6649,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["t = torch.tensor([[1,2],[3,4]])\n","print(torch.gather(t, 1, torch.tensor([[0,0],[1,0]])))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["tensor([[1, 1],\n","        [4, 3]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7tWhFr1eGpiH","colab_type":"text"},"source":["`torch.gather` creates a new tensor from the input tensor by taking the values from each row along the input dimension `dim`. The values in `torch.LongTensor`, passed as `index`, specify which value to take from each 'row'. The dimension of the output tensor is same as the dimension of index tensor. Following illustration from the official docs explains it more clearly:\n","\n","![alt text](https://i.stack.imgur.com/nudGq.png)\n","\n","(Note: In the illustration, indexing starts from 1 and not 0).\n","\n","In first example, the dimension given is along rows (top to bottom), so for (1,1) position of `result`, it takes row value from the `index` for the `src` that is `1`. At (1,1) in source value is `1` so, outputs `1` at (1,1) in `result`. Similarly for (2,2) the row value from the index for `src` is `3`. At (3,2) the value in `src` is `8` and hence outputs `8` and so on.\n","\n","Similarly for second example, indexing is along columns, and hence at (2,2) position of the `result`, the column value from the index for `src` is `3`, so at (2,3) from `src` ,`6` is taken and outputs to `result` at (2,2)\n","\n","Source of this text cell : https://stackoverflow.com/a/54706716/6644968\n","\n"]},{"cell_type":"code","metadata":{"id":"auw0dr4uLteh","colab_type":"code","outputId":"edc6d391-c5ed-47b5-aea3-6d4de4e3a673","executionInfo":{"status":"ok","timestamp":1590592756036,"user_tz":-330,"elapsed":6636,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["src = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n","index = torch.LongTensor([[0, 1, 2], [1, 2, 0]])\n","result = torch.gather(input = src, dim = 0, index = index)\n","print(result)\n","# The position of elements of result w.r.t src matrix can be written as follows\n","# result = [[(0, 0), (1, 1), (2, 2)] [(1, 0), (2, 1), (0, 2)]]"],"execution_count":22,"outputs":[{"output_type":"stream","text":["tensor([[1, 5, 9],\n","        [4, 8, 3]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"j49xhkZ1x3X9","colab_type":"text"},"source":["**NOTE:**\n","\n","`dim` in PyTorch is similar to `axis` in NumPy. Its actually bit tricky to visualize these concepts when learning about them initially. The following resources will help in gaining intuition for the same.\n","* [Resource 1](https://www.youtube.com/watch?v=nS0oKBbNjWY)\n","* [Resource 2](https://www.sharpsightlabs.com/blog/numpy-axes-explained/)\n","* [Resource 3](https://towardsdatascience.com/understanding-dimensions-in-pytorch-6edf9972d3be)\n","* [Resource 4](https://medium.com/@aerinykim/numpy-sum-axis-intuition-6eb94926a5d1)"]},{"cell_type":"markdown","metadata":{"id":"PZKX1yClOTEf","colab_type":"text"},"source":["### `torch.squeeze`\n","\n","![alt text](https://drive.google.com/uc?id=1ohtcSu0VKZF8b68mXRGXvciEln8ycuXH)"]},{"cell_type":"code","metadata":{"id":"fmVf-s28PJCS","colab_type":"code","outputId":"360badec-2d5c-438d-fad8-3d9d93e1f331","executionInfo":{"status":"ok","timestamp":1590592756037,"user_tz":-330,"elapsed":6625,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["x = torch.zeros(2, 1, 2, 1, 2)\n","print(x.size())\n","\n","y = torch.squeeze(x)\n","print(y.size())\n","\n","y = torch.squeeze(x, 0)\n","print(y.size())\n","\n","y = torch.squeeze(x, 1)\n","print(y.size())"],"execution_count":23,"outputs":[{"output_type":"stream","text":["torch.Size([2, 1, 2, 1, 2])\n","torch.Size([2, 2, 2])\n","torch.Size([2, 1, 2, 1, 2])\n","torch.Size([2, 2, 1, 2])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BZreeUG5PvxT","colab_type":"text"},"source":["### `torch.unsqueeze`\n","\n","![alt text](https://drive.google.com/uc?id=1cQ7qLk3gtWZB6O70Un5VNJBH7L5_41Wp)"]},{"cell_type":"code","metadata":{"id":"BqnpeffmQEM7","colab_type":"code","outputId":"6368e498-100d-40de-8468-515d9a724b5a","executionInfo":{"status":"ok","timestamp":1590592756038,"user_tz":-330,"elapsed":6614,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["x = torch.tensor([1, 2, 3, 4])\n","print(x.size())\n","print(\"*\" * 65)\n","\n","print(torch.unsqueeze(x, 0))\n","print((torch.unsqueeze(x, 0)).size())\n","print(\"*\" * 65)\n","\n","print(torch.unsqueeze(x, 1))\n","print((torch.unsqueeze(x, 1)).size())\n","print(\"*\" * 65)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["torch.Size([4])\n","*****************************************************************\n","tensor([[1, 2, 3, 4]])\n","torch.Size([1, 4])\n","*****************************************************************\n","tensor([[1],\n","        [2],\n","        [3],\n","        [4]])\n","torch.Size([4, 1])\n","*****************************************************************\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hSo-C8_MRGdO","colab_type":"text"},"source":["### Putting it together (`gather` and `squeeze`)\n","\n","In PyTorch you can perform the same operation using the `gather()` method. If `s` is a PyTorch Tensor of shape `(N, C)` and `y` is a PyTorch Tensor of shape `(N,)` containing longs in the range `0 <= y[i] < C`, then\n","\n","`s.gather(1, y.view(-1, 1)).squeeze()`\n","\n","will be a PyTorch Tensor of shape `(N,)` containing one entry from each row of `s`, selected according to the indices in `y`.\n","\n","run the following cell to see an example."]},{"cell_type":"code","metadata":{"id":"hlva6Cf8RQNS","colab_type":"code","outputId":"cf75a8cb-ec3b-47c9-909e-3e8cb0e62109","executionInfo":{"status":"ok","timestamp":1590592756040,"user_tz":-330,"elapsed":6602,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# Example of using gather to select one entry from each row in PyTorch\n","def gather_example():\n","    N, C = 4, 5\n","    s = torch.randn(N, C)\n","    y = torch.LongTensor([1, 2, 1, 3])\n","    print(s)\n","    print(y)\n","    print(s.gather(1, y.view(-1, 1)).squeeze())\n","gather_example()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["tensor([[ 0.5562, -2.3713, -0.7690, -0.5957,  0.3673],\n","        [-0.1252, -0.4316, -0.1369,  0.2187,  2.6047],\n","        [ 0.2975,  1.2903,  0.2209,  0.4667,  0.6130],\n","        [-1.0303,  0.0174,  0.1998,  0.8787,  1.5550]])\n","tensor([1, 2, 1, 3])\n","tensor([-2.3713, -0.1369,  1.2903,  0.8787])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mO8GaErvSYRP","colab_type":"text"},"source":["### `torch.max`\n","\n","![alt text](https://drive.google.com/uc?id=1BWyunoD1xey8MRuADi9iSpBBrkS3TUL1)"]},{"cell_type":"code","metadata":{"id":"bn3nK2haTB4o","colab_type":"code","outputId":"b2cc77ab-05eb-41c7-adfc-007145d08729","executionInfo":{"status":"ok","timestamp":1590592756041,"user_tz":-330,"elapsed":6590,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["a = torch.randn(1, 3)\n","print(a)\n","\n","print(torch.max(a))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["tensor([[-0.2067, -0.7156,  0.7224]])\n","tensor(0.7224)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z-xmOAAxTeoE","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=184CwB5REsibX8RpXNfN_xVnXVhwG-rjj)"]},{"cell_type":"code","metadata":{"id":"_amQYAnzTov0","colab_type":"code","outputId":"259a6e2e-1068-47e6-af5b-58d0d39ab55a","executionInfo":{"status":"ok","timestamp":1590592756042,"user_tz":-330,"elapsed":6578,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["a = torch.randn(4, 4)\n","print(a)\n","print(\"*\" * 65)\n","\n","print(torch.max(a, dim = 1))\n","print(\"*\" * 65)\n","\n","values, indices = torch.max(a, 1)\n","print(values)\n","print(indices)\n","print(\"*\" * 65)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0527,  0.0126, -0.2024,  0.9487],\n","        [ 0.5723, -1.2748, -0.7612, -0.8935],\n","        [ 0.4131,  0.7309,  0.1183, -0.4827],\n","        [ 0.1957,  0.8081, -0.9771, -0.0841]])\n","*****************************************************************\n","torch.return_types.max(\n","values=tensor([0.9487, 0.5723, 0.7309, 0.8081]),\n","indices=tensor([3, 0, 1, 1]))\n","*****************************************************************\n","tensor([0.9487, 0.5723, 0.7309, 0.8081])\n","tensor([3, 0, 1, 1])\n","*****************************************************************\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zl2eh7fcUl_p","colab_type":"text"},"source":["![alt text](https://drive.google.com/uc?id=13aDh2cQ0pw8zROcV1rZIqdAMs4uwUmQ6)"]},{"cell_type":"code","metadata":{"id":"1mgOb5TNUuez","colab_type":"code","outputId":"af435634-db55-4882-c190-655a9b6252a9","executionInfo":{"status":"ok","timestamp":1590592756043,"user_tz":-330,"elapsed":6568,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["a = torch.randn(4)\n","print(a)\n","b = torch.randn(4)\n","print(b)\n","print(torch.max(a, b))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["tensor([ 0.0737, -0.9813,  0.1793, -0.1010])\n","tensor([ 0.0576, -0.8531,  0.4598, -0.3327])\n","tensor([ 0.0737, -0.8531,  0.4598, -0.1010])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S2alOeDPVBh9","colab_type":"text"},"source":["### `torch.abs()`\n","\n","![alt text](https://drive.google.com/uc?id=1-XwicMO-HPvMDhYKxIHGxi8qgctUDNUl)"]},{"cell_type":"markdown","metadata":{"id":"dQMtso26V8Xw","colab_type":"text"},"source":["### `torch.cat`\n","\n","![alt text](https://drive.google.com/uc?id=1gN9UzU_zBoG36dkV-r-iSyPil3AmPX09)"]},{"cell_type":"code","metadata":{"id":"f5bR3JECWJCu","colab_type":"code","outputId":"54e2ee02-f0db-4c7c-c547-c4da8c262f26","executionInfo":{"status":"ok","timestamp":1590592756045,"user_tz":-330,"elapsed":6561,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["x = torch.randn(2, 3)\n","print(x)\n","print(x.size())\n","print(\"*\" * 65)\n","\n","print(torch.cat((x, x, x), 0))\n","print((torch.cat((x, x, x), 0)).size())\n","print(\"*\" * 65)\n","\n","print(torch.cat((x, x, x), 1))\n","print((torch.cat((x, x, x), 1)).size())\n","print(\"*\" * 65)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["tensor([[-1.1953,  1.7962,  0.3583],\n","        [ 0.4639, -0.8959, -0.2181]])\n","torch.Size([2, 3])\n","*****************************************************************\n","tensor([[-1.1953,  1.7962,  0.3583],\n","        [ 0.4639, -0.8959, -0.2181],\n","        [-1.1953,  1.7962,  0.3583],\n","        [ 0.4639, -0.8959, -0.2181],\n","        [-1.1953,  1.7962,  0.3583],\n","        [ 0.4639, -0.8959, -0.2181]])\n","torch.Size([6, 3])\n","*****************************************************************\n","tensor([[-1.1953,  1.7962,  0.3583, -1.1953,  1.7962,  0.3583, -1.1953,  1.7962,\n","          0.3583],\n","        [ 0.4639, -0.8959, -0.2181,  0.4639, -0.8959, -0.2181,  0.4639, -0.8959,\n","         -0.2181]])\n","torch.Size([2, 9])\n","*****************************************************************\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RxNQDZRHS1vJ","colab_type":"text"},"source":["## NumPy Bridge\n","Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n","\n","The Torch Tensor and NumPy array will share their underlying memory locations (if the Torch Tensor is on CPU), and changing one will change the other."]},{"cell_type":"markdown","metadata":{"id":"r5xfCT4dS5lA","colab_type":"text"},"source":["### Converting a Torch Tensor to a NumPy Array"]},{"cell_type":"code","metadata":{"id":"a-NmjHilS744","colab_type":"code","outputId":"cd5cbcbe-56ba-41f0-84d1-094fb4750a69","executionInfo":{"status":"ok","timestamp":1590592756046,"user_tz":-330,"elapsed":6552,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["a = torch.ones(5)\n","print(a)\n","print(a.size())"],"execution_count":30,"outputs":[{"output_type":"stream","text":["tensor([1., 1., 1., 1., 1.])\n","torch.Size([5])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X7N-_3fiTAWk","colab_type":"code","outputId":"47005237-f402-48d3-9356-eabe56d835f8","executionInfo":{"status":"ok","timestamp":1590592756048,"user_tz":-330,"elapsed":6546,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["b = a.numpy()\n","print(b)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[1. 1. 1. 1. 1.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_uWC2vFxTBpW","colab_type":"text"},"source":["See how the numpy array changed in value."]},{"cell_type":"code","metadata":{"id":"EsKdyN5STDNH","colab_type":"code","outputId":"ee5521ac-f764-41b1-a513-e7fc1e7ab5c8","executionInfo":{"status":"ok","timestamp":1590592756049,"user_tz":-330,"elapsed":6539,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["a.add_(1)\n","print(a)\n","print(b)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rQib6-EoTLOi","colab_type":"text"},"source":["### Converting NumPy Array to Torch Tensor\n","See how changing the np array changed the Torch Tensor automatically"]},{"cell_type":"code","metadata":{"id":"3bEEEpOPTObt","colab_type":"code","outputId":"e06d1b5c-5899-4bec-fec4-970140db7d22","executionInfo":{"status":"ok","timestamp":1590592756051,"user_tz":-330,"elapsed":6532,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","np.add(a, 1, out=a)\n","print(a)\n","print(b)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"igZaKvfeTQGZ","colab_type":"text"},"source":["All the Tensors on the CPU except a CharTensor support converting to NumPy and back."]},{"cell_type":"markdown","metadata":{"id":"LlNmFYAfTV2Q","colab_type":"text"},"source":["## CUDA Tensors"]},{"cell_type":"markdown","metadata":{"id":"mRFNa91rTfdn","colab_type":"text"},"source":["Tensors can be moved onto any device using the `.to` method."]},{"cell_type":"code","metadata":{"id":"L8A-ucQxTgWB","colab_type":"code","colab":{}},"source":["# let us run this cell only if CUDA is available\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")          # a CUDA device object\n","    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n","    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n","    z = x + y\n","    print(z)\n","    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xX2s1o-m5r1_","colab_type":"text"},"source":["One more way to use GPU (a more common approach) in Pytorch is as follows:"]},{"cell_type":"code","metadata":{"id":"PqsqOWUZ513N","colab_type":"code","outputId":"b6c42ec1-8030-4104-c418-c8f6fd473d38","executionInfo":{"status":"ok","timestamp":1590592756053,"user_tz":-330,"elapsed":6522,"user":{"displayName":"Darshan Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi9rJ96_FUlkKwATDmDI4uA1p05C1MirD-yLWNyRg=s64","userId":"08607213967965377720"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["cpu\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"faXy_9cF6Lev","colab_type":"text"},"source":["You can move data to the GPU by doing `.to(device)` "]},{"cell_type":"code","metadata":{"id":"uKVoL1sA6eJt","colab_type":"code","colab":{}},"source":["data = torch.eye(3)\n","data = data.to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B_hz0WlIE5ko","colab_type":"text"},"source":["Bottomline is you can do pretty much everything just by using only Tensors!"]},{"cell_type":"markdown","metadata":{"id":"coqdjTTe_5zI","colab_type":"text"},"source":["# References\n","\n","1.   [Deep Learning with PyTorch: A 60 minute blitz, Soumith Chintala](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n","\n","2.   [TORCH](https://pytorch.org/docs/stable/torch.html)\n","\n","3. [Stefan Otte: Deep Neural Networks with PyTorch | PyData Berlin 2018](https://www.youtube.com/watch?v=_H3aw6wkCv0&t=821s)\n","\n","4. [CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)\n","\n","\n","\n"]}]}